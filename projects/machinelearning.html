<!DOCTYPE html>
<html>
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-131669567-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-131669567-1');
</script>
<!-- End google Code -->
<!-- Matomo -->
<script type="text/javascript">
  var _paq = _paq || [];
  /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
  _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
  _paq.push(["setCookieDomain", "*.jlivingston01.github.io"]);
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u="https://jlivingston01.matomo.cloud/";
    _paq.push(['setTrackerUrl', u+'piwik.php']);
    _paq.push(['setSiteId', '1']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.type='text/javascript'; g.async=true; g.defer=true; g.src='//cdn.matomo.cloud/jlivingston01.matomo.cloud/piwik.js'; s.parentNode.insertBefore(g,s);
  })();
</script>
<!-- End Matomo Code -->
<!-- Matomo Image Tracker-->
<noscript>
<img src="https://jlivingston01.matomo.cloud/piwik.php?idsite=1&amp;rec=1&amp;action_name=machinelearning" style="border:0" alt="" />
</noscript>
<!-- End Matomo -->
</head>
<body>
<header id="header" class="alt">
					<h1><a href="../index.html">JLIV's Github Site</a></h1>
					<nav id="nav">
						<ul>
							<li><a href="../index.html">Home</a></li>
							<li><a href="../bio.html" class="button">Bio</a></li>
							<li><a href="../projects.html" class="button">Projects</a></li>
							<!-- li>
								<a href="#" class="icon fa-angle-down">Layouts</a>
								<ul>
									<li><a href="generic.html">Generic</a></li>
									<li><a href="contact.html">Contact</a></li>
									<li><a href="elements.html">Elements</a></li>
									<li>
										<a href="#">Submenu</a>
										<ul>
											<li><a href="#">Option One</a></li>
											<li><a href="#">Option Two</a></li>
											<li><a href="#">Option Three</a></li>
											<li><a href="#">Option Four</a></li>
										</ul>
									</li>
								</ul>
							</li -->
						</ul>
					</nav>
				</header>
<h1>Engineering a Machine Learning Model</h1>
<p>
<br>
<h3>Background</h3>
I used to focus about half of my working efforts on business analytics. I wanted to know, foremost, how marketing  <br>
would affect the growth and health of businesses, but I also needed to understand how the maturity of businesses   <br>
affects the effectiveness of marketing. I resolved that growth-curve modeling may be a reasonable approximation for<br>
the maturity of a startup. <br>
<h3>The Data</h3>
In practice, I researched this concept and implemented a test using a company's Key Performance Indicator. In this <br>
demonstration, have pulled normalized Google search volume from Google Trends for two different companies          <br>
(subscription model startups) in order to demonstrate the concepts I applied. It may be helpful to consider the KPI<br>
here "Cumulative Google Search Volume over time".<br>
<h3>Approach</h3>
While working with Mixed Media Models, I was introduced to an interesting feature transformation function, the Hill<br>
transformation, a sigmoidal equation that can assume many shapes as dictated by its parameters. The goal of my     <br>
exercise became to fit the Hill equation parameters to some normalized-cumulative business KPI data using time     <br>
as the predictor, scale the resulting fit to the non-normalized KPI data, and project future KPI values.<br>
 <div class="item active">
      <img src="/images/hill.png" alt="Hill" class="jayimage">
    </div>
Here, t represents the time unit, s is a shape parameter, k is the point t of T where Hill(t) is one-half of t, and<br>
c is an introduced parameter to make this equation asymptotic between 0 and c, allowing projections of normalized  <br>
data to surpass the historical maximum. <br>
<h3>Designing a Machine Learning Algorithm</h3>
In order to learn parameters k, s and c, where the cumulative data is represented by some function Hill(t,k,s,c), I<br>
calculate the partial derivatives of some cost function in terms of each parameter, then use these partial         <br>
derivatives to update parameter estimates in a gradient descent. In this implementation, I create an on-line       <br>
gradient descent, updating parameter estimates when evaluating at each observation during each epoch. Below are the<br>
cost function and the partial derivatives that I am using. <br>
 <div class="item active">
      <img src="/images/error_gradients.png" alt="error_grads" class="jayimage">
    </div>
It is clear that the first multiplicative term in each partial derivative is simply the error of the prediction,   <br>
and the remaining terms are the partial derivatives of the Hill function itself. When I implement, I calculate the <br>
error and the partial derivates of the Hill function in terms of each parameter, and multiply by the learning    <br>
rate to update parameter estimates. Parameter estimates are updated iteravely as:<br>
 <div class="item active">
      <img src="/images/param_updates.png" alt="Hill" class="jayimage">
    </div>
<h3>Algorithm Functions</h3>
Below are the functions I write to implement the fitting of this sigmoidal model.<br><br>
<!--style>.indented {
  padding-left: 50pt;
  padding-right: 50pt;
}</style>
<style>.tab {
  padding-left: 50pt;
}</style>
<div class="indented"-->
<p><blockquote><pre>
def HILL(x,k,s,c):
    h = c/(1+(x/k)**(-s))
    return h
</pre></blockquote></p>
<p><blockquote><pre>
def normalize(d):
    d = np.array(d)
    dnorm = (d - min(d))/(max(d)-min(d))
    min_norm = min(d)
    max_norm = max(d)
    return(dnorm,min_norm,max_norm)
</pre></blockquote></p>
<p><blockquote><pre>
def de_normalize(dnorm,min_norm,max_norm):
    dnorm = np.array(dnorm)
    d = dnorm*(max_norm - min_norm)+min_norm
    return(d)
</pre></blockquote></p>

<p><blockquote><pre>
#This fit function normalizes the target Y between 0 and 1 (ynorm)
#Calculates the Hill function of the initial k,s,c
#Evaluates the error of Hill from ynorm
#Updates estimates of k,s,c using learning rate a and the partial derivative of k,s,c

def HILL_fit(d,epoch = 200, a = .1,init = 0, s = 1.9, k_perc = 2, c_init = 1.3):
    y,k,s,c = d,len(d)/k_perc,s,c_init
    ynorm,min_norm,max_norm = normalize(y)
    for j in range(epoch):
        for i in range(1+init,len(ynorm)+1+init):
            k,s,c = k + a*(c*((1/((1+(i/k)**(-s))**(2)))*(s)*(i/k)**((-s-1)))*(-i)/(k**2))*(ynorm[i-1-init] - HILL(i,k,s,c)),\
                    s + a*(c*(1/((1+(i/k)**(-s))**2))*math.log(i/k)*(i/k)**(-s))*(ynorm[i-1-init] - HILL(i,k,s,c)),\
                    c + a*(1/((1+(i/k)**(-s))))*(ynorm[i-1-init] - HILL(i,k,s,c))

    fit = []
    for i in range(1+init,len(d)+1+init):
        h_pred = HILL(i,k,s,c)
        fit.append(h_pred)
    
    return fit,k,s,c,min_norm,max_norm
	
def hill_proj(k,s,p, c,init = 0):
    k = k
    s = s
    projection = []
    for i in p:
        h = HILL(i+init+1,k,s,c)
        projection.append(h)
    return(projection)
</pre></blockquote></p>
<h3>Outcomes and Implications</h3>

 <div class="item active">
      <img src="/images/c1_cume.png" alt="Hillfit" class="jayimage">
    </div>
<br>

</p>
<li><a href="/projects/hill_fit.html"  target="_blank">See the Script</a></li>
</body>
</html>