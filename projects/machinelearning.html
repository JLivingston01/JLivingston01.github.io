<!DOCTYPE html>
<html>
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-131669567-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-131669567-1');
</script>
<!-- End google Code -->
<!-- Matomo -->
<script type="text/javascript">
  var _paq = _paq || [];
  /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
  _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
  _paq.push(["setCookieDomain", "*.jlivingston01.github.io"]);
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u="https://jlivingston01.matomo.cloud/";
    _paq.push(['setTrackerUrl', u+'piwik.php']);
    _paq.push(['setSiteId', '1']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.type='text/javascript'; g.async=true; g.defer=true; g.src='//cdn.matomo.cloud/jlivingston01.matomo.cloud/piwik.js'; s.parentNode.insertBefore(g,s);
  })();
</script>
<!-- End Matomo Code -->
<!-- Matomo Image Tracker-->
<noscript>
<img src="https://jlivingston01.matomo.cloud/piwik.php?idsite=1&amp;rec=1&amp;action_name=machinelearning" style="border:0" alt="" />
</noscript>
<!-- End Matomo -->
</head>
<body>
<header id="header" class="alt">
					<h1><a href="../index.html">JLIV's Github Site</a></h1>
					<nav id="nav">
						<ul>
							<li><a href="../index.html">Home</a></li>
							<li><a href="../bio.html" class="button">Bio</a></li>
							<li><a href="../projects.html" class="button">Projects</a></li>
							<!-- li>
								<a href="#" class="icon fa-angle-down">Layouts</a>
								<ul>
									<li><a href="generic.html">Generic</a></li>
									<li><a href="contact.html">Contact</a></li>
									<li><a href="elements.html">Elements</a></li>
									<li>
										<a href="#">Submenu</a>
										<ul>
											<li><a href="#">Option One</a></li>
											<li><a href="#">Option Two</a></li>
											<li><a href="#">Option Three</a></li>
											<li><a href="#">Option Four</a></li>
										</ul>
									</li>
								</ul>
							</li -->
							<li><a href="../page1.html" class="button">Page 1</a></li>
							<li><a href="../page3.html" class="button">The Long Page</a></li>
						</ul>
					</nav>
				</header>
<h1>Engineering a Machine Learning Model</h1>
<p>
<br>
<h3>Background</h3><br>
I used to focus about half of my working efforts on business analytics. I wanted to know, foremost, how marketing  <br>
would affect the growth and health of businesses, but I also needed to understand how the maturity of businesses   <br>
affects the effectiveness of marketing. I resolved that growth-curve modeling may be a reasonable approximation for<br>
the maturity of a startup. <br>
<h3>The Data</h3><br>
In practice, I researched this concept and implemented a test using a company's Key Performance Indicator. In this <br>
demonstration, have pulled normalized Google search volume from Google Trends for a different company (a start up) <br>
in order to demonstrate the concepts I applied. It may be helpful to consider the KPI here "Cumulative Google      <br>
Search Volume over time".<br>
<h3>Approach</h3><br>
While working with Mixed Media Models, I was introduced to an interesting feature transformation function, the Hill<br>
transformation, a sigmoidal equation that can assume many shapes as dictated by its parameters. The goal of my     <br>
exercise became to fit the Hill equation parameters to some normalized-cumulative business KPI data using time     <br>
intervals as the predictor, scale the resulting fit to the non-normalized KPI data, and project future data points.<br>
 <div class="item active">
      <img src="/images/hill.png" alt="Hill" class="jayimage">
    </div>
<br>
Here, t represents the time unit, s is a shape parameter, k is the point t of T where Hill(t) is one-half of t, and<br>
c is an introduced parameter to make this equation asymptotic between 0 and c, allowing projections of normalized  <br>
data to surpass the historical maximum. <br>
<h3>Designing the Machine to Learn</h3><br>
In order to learn parameters k, s and c, where the cumulative data is represented by some function Hill(t,k,s,c), I<br>
calculate the partial derivatives of some cost function in terms of each parameter, then use these partial         <br>
derivatives to update parameter estimates in a gradient descent. In this implementation, I create an on-line       <br>
gradient descent, updating parameter estimates when evaluating at each observation during each epoch. Below are the<br>
cost function and the partial derivatives that I am using. <br>
 <div class="item active">
      <img src="/images/error_gradients.png" alt="error_grads" class="jayimage">
    </div>
<br>
It is clear that the first multiplicative term in each partial derivative is simply the error of the prediction,   <br>
and the remaining terms are the partial derivatives of the Hill function itself. When I implement, I calculate the <br>
error and the partial derivates of the Hill function in terms of each parameter, and multiply by the learning    <br>
rate to update parameter estimates.<br>
<h3>Functionalizing the Script</h3><br>
Below are the functions I write to implement the fitting of this sigmoidal model.<br>

<div class="indented">
def HILL(x,k,s,c):<br>
    h = c/(1+(x/k)**(-s))<br>
    return h<br>
<br>
def normalize(d):<br>
    d = np.array(d)<br>
    dnorm = (d - min(d))/(max(d)-min(d))<br>
    min_norm = min(d)<br>
    max_norm = max(d)<br>
    return(dnorm,min_norm,max_norm)<br>
<br>
def de_normalize(dnorm,min_norm,max_norm):<br>
    dnorm = np.array(dnorm)<br>
    d = dnorm*(max_norm - min_norm)+min_norm<br>
    return(d)<br>
<br>
#This fit function normalizes the target Y between 0 and 1 (ynorm)<br>
#Calculates the Hill function of the initial k,s,c<br>
#Evaluates the error of Hill from ynorm<br>
#Updates estimates of k,s,c using learning rate a and the partial derivative of k,s,c<br>
<br>
def HILL_fit(d,epoch = 200, a = .1,init = 0, s = 1.9, k_perc = 2, c_init = 1.3):<br>
    y = d<br>
    k = len(d)/k_perc<br>
    s = s<br>
    c = c_init<br>
    ynorm,min_norm,max_norm = normalize(y)<br>
    for j in range(epoch):<br>
        for i in range(1+init,len(ynorm)+1+init):<br>
            h = HILL(i,k,s,c)<br>
            grad_k = c*((1/((1+(i/k)**(-s))**(2)))*(s)*(i/k)**((-s-1)))*(-i)/(k**2)<br>
            grad_s = c*(1/((1+(i/k)**(-s))**2))*math.log(i/k)*(i/k)**(-s)<br>
            grad_c = 1/((1+(i/k)**(-s)))<br>
            e = ynorm[i-1-init] - h<br>
            k = k + a*3*grad_k*e<br>
            s = s + a*grad_s*e<br>
            c = c + a*grad_c*e<br>
    <br>
    fit = []<br>
    for i in range(1+init,len(d)+1+init):<br>
        h_pred = HILL(i,k,s,c)<br>
        fit.append(h_pred)<br>
    <br>
    return fit,k,s,c,min_norm,max_norm<br>
	</div>
</p>
</body>
</html>